---
layout: page
title: Resume
permalink: /resume/
---

# Resume

<div class="resume-section">
  <p class="resume-download">
    <a href="{{ '/assets/pdf/CyanResumePublic.pdf' | relative_url }}" target="_blank" class="btn">
      <i class="fas fa-file-pdf"></i> Download PDF Resume
    </a>
  </p>
</div>

## Education

**Pennsylvania State University**, University Park, PA  
*Ph.D. in Computer Science and Engineering* (2018-2025, Expected)  
Advisors: Dr. Mahmut Taylan Kandemir, Dr. Jack Sampson  
GPA: 3.7/4.0

**National Institute of Technology, Rourkela**, India  
*B.Tech. + M.Tech. Dual Degree in Electronics and Communication Engineering* (2011-2016)  
Advisors: Dr. Sarat Kumar Patra, Tarjinder Singh (Intel)  
CGPA: 8.39/10.00 (Honors)

## Professional Experience

**Graduate Research Assistant**, Microsystems Design Lab, Penn State (2018-Present)
- Led hardware/software co-design initiatives for ML systems at scale, optimizing performance, energy efficiency, and resource utilization across heterogeneous computing platforms
- Developed novel architectural solutions for efficient deployment of large language models on resource-constrained devices, achieving up to 22% accuracy improvement with minimal computational overhead
- Engineered high-throughput computational storage architectures for data-intensive ML workloads, reducing data movement by 6.1Ã— while maintaining system-level performance
- Created comprehensive performance modeling frameworks for multi-dimensional optimization of ML deployments, balancing latency, accuracy, and energy constraints in both edge and cloud environments

**Research Intern**, Bell Labs (Summer 2021)
- Developed optimization strategies for autonomous ML inference serving across heterogeneous hardware (GPUs, FPGAs), leveraging Apache TVM for cross-platform kernel optimization
- Implemented model compression techniques including quantization, pruning, and knowledge distillation to improve inference efficiency while maintaining accuracy targets

**Design Engineer**, Intel (2016-2018)
- Led hardware/software co-design initiatives for ML accelerators, implementing systematic performance modeling methodologies for GPU and FPGA platforms
- Optimized ML kernels (convolution, softmax) for FPGA deployment, balancing computational efficiency with resource utilization through microarchitectural innovations
- Conducted comprehensive timing analysis and workload characterization for large-scale ML deployment across heterogeneous computing environments
- Developed simulation frameworks to validate accelerator designs, enabling rapid iteration and performance optimization prior to physical deployment

**Research Intern**, Intel (2015-2016)
- Designed FPGA-based hardware accelerators for protein search algorithms, achieving significant speedups over CPU implementations
- Leveraged OpenCL for rapid deployment and optimization of bioinformatics kernels (pairHMM, HMMer) on FPGA platforms, establishing performance benchmarks for production environments

**Research Intern**, Indian Institute of Technology, Bombay (Summer 2014)
- Designed algorithms and framework for hyperspectral image processing
- Leveraged MATLAB and atmospheric data to build atmospheric corrections for hyperspectral images

**Research Intern**, Center for AI and Robotics, DRDO (Summer 2013)
- Designed novel algorithm and mathematical modeling for generic azimuthal map projection

## Technical Expertise

**Programming/Compiler**: Python, C++, LLVM, Apache TVM

**Hardware Architecture**: Microarchitecture, FPGA, ReRAM crossbars, Systolic arrays, Low-power systems

**Accelerator Programming**: CUDA toolkit, OpenCL, Low-precision computing, Parallel programming optimization

**ML Systems**: TensorFlow, PyTorch, Quantization, Pruning, Kernel optimization

**Performance Engineering**: Workload characterization, Power/Performance modeling, Microarchitecture simulation, profiling tools (Nsight, vTune, Pin tool, Valgrind)

**Hardware Design**: SystemVerilog, Xilinx Vivado, Design Compiler, Hardware simulation

## Awards & Honors

- Best Paper Nomination, Design Automation and Test in Europe (DATE), 2021
- Student Travel Award, IEEE Network Architecture and Storage (NAS), 2021

## Selected Publications

For a complete list of publications, please visit the [Publications](/publications/) page.

1. **NExUME: Adaptive Training and Inference for DNNs under Intermittent Power Environments**  
   Cyan S. Mishra, Deeksha Chaudhary, Jack Sampson, Mahmut Taylan Kandemir, and Chita R. Das  
   *International Conference on Learning Representations (ICLR), 2025*

2. **Usas: A Sustainable Continuous-Learning Framework for Edge Servers**  
   Cyan S. Mishra, Jack Sampson, Mahmut Taylan Kandemir, Vijaykrishnan Narayanan and Chita R. Das  
   *IEEE International Symposium on High-Performance Computer Architecture (HPCA), 2024*

3. **Cocktail: A Multidimensional Optimization for Model Serving in Cloud**  
   Jashwant Raj Gunasekharan, Cyan S. Mishra, Prashanth Thinakaran, Bikash Sharma, Mahmut T Kandemir, Chita R. Das  
   *USENIX Symposium on Networked Systems Design and Implementation (NSDI), 2022*

4. **Origin: Enabling On-Device Intelligence for Human Activity Recognition Using Energy Harvesting Wireless Sensor Networks**  
   Cyan S. Mishra, Jack Sampson, Mahmut T Kandemir, Vijaykrishnan Narayanan  
   *Design, Automation & Test in Europe Conference (DATE), 2021* [Best Paper Nominee]

5. **An Efficient Edge-Cloud Partitioning of Random Forests for Distributed Sensor Networks**  
   Tianyi Shen, Cyan S. Mishra, Jack Sampson, Mahmut Taylan Kandemir, Vijaykrishnan Narayanan  
   *IEEE Embedded Systems Letters, 2022*
